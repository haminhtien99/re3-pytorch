{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzlVBg8LRLHxmGoM386itu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haminhtien99/re3-pytorch/blob/master/home.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYucsTa8vcj",
        "outputId": "51028c98-2062-427b-c881-fb5499256dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch\n",
        "# !git clone https://github.com/danielgordon10/re3-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC3cnQtm9Isl",
        "outputId": "ff82b74d-cc4d-4f90-8fcd-2323508fe595"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Chuẩn bị dataset dùng để huấn luyện mạng\n"
      ],
      "metadata": {
        "id": "8IyyjraDUe34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gồm 2 thư mục images và labels. Mỗi thư mục chia thành hai thư mục con là train/test\n",
        "* images --- train/test ---files .jpg\n",
        "* labels --- train/test\n",
        "  * files .txt: tên các file trong images\n",
        "  * files .npy: Chứa thông tin về boungding box và các thuộc tính class, video, imgNum"
      ],
      "metadata": {
        "id": "oBr0Un7d2OkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import shutil"
      ],
      "metadata": {
        "id": "7d8iTIreDcLz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/demo/data/\"\n",
        "dest_folder = \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/data/\"\n",
        "jpg_files = [f for f in os.listdir(source_folder) if f.endswith(\".jpg\")]\n",
        "jpg_files.sort()\n",
        "num_train = len(jpg_files)//3 * 2\n",
        "\n",
        "img_train = jpg_files[:num_train]\n",
        "img_test = jpg_files[num_train:]\n",
        "for img in img_train:\n",
        "    source_path = source_folder + img\n",
        "    dest_path = dest_folder + \"/images/train/\"\n",
        "    if not os.path.exists(dest_path):\n",
        "        os.makedirs(dest_path)\n",
        "    shutil.copy(source_path, dest_path)\n",
        "for img in img_test:\n",
        "    source_path = source_folder + img\n",
        "    dest_path = dest_folder + \"/images/test/\"\n",
        "    if not os.path.exists(dest_path):\n",
        "        os.makedirs(dest_path)\n",
        "    shutil.copy(source_path, dest_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "92eVj199F-h8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path = dest_folder + \"labels/train/\"\n",
        "test_labels_path = dest_folder  + \"labels/test/\"\n",
        "if not os.path.exists(train_labels_path):\n",
        "    os.makedirs(train_labels_path)\n",
        "if not os.path.exists(test_labels_path):\n",
        "    os.makedirs(test_labels_path)\n",
        "with open(train_labels_path+ \"images.txt\", 'w') as file:\n",
        "    for img in img_train:\n",
        "        file.write(img + '\\n')\n",
        "with open(test_labels_path+ \"images.txt\", 'w') as file:\n",
        "    for img in img_test:\n",
        "        file.write(img + '\\n')"
      ],
      "metadata": {
        "id": "UdtqfzVrAfmH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_txt = source_folder +\"labels.txt\"\n",
        "with open(labels_txt, 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "bboxes = []\n",
        "imNum = 1\n",
        "for line in lines[:num_train]:\n",
        "    # print(line)\n",
        "    line = [int(float(number)) for number in line.split()]\n",
        "\n",
        "    videoId = 0\n",
        "    trackId = 0\n",
        "    classId = 0\n",
        "    occl = 0\n",
        "    bbox = [line[1], line[2], line[3], line[4], videoId, trackId, imNum, classId, occl]\n",
        "    bboxes.append(bbox)\n",
        "    imNum += 1\n",
        "bboxes = np.array(bboxes)\n",
        "# print(bboxes)\n",
        "\n",
        "if not os.path.exists(train_labels_path):\n",
        "    os.makedirs(train_labels_path)\n",
        "np.save(train_labels_path + \"/labels.npy\", bboxes)\n"
      ],
      "metadata": {
        "id": "S34WDFB7LPMm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bboxes = []\n",
        "imNum = 1\n",
        "for line in lines[num_train:]:\n",
        "    # print(line)\n",
        "    line = [int(float(number)) for number in line.split()]\n",
        "    # imNum =  line[0]\n",
        "    videoId = 0\n",
        "    trackId = 0\n",
        "    classId = 0\n",
        "    occl = 0\n",
        "    bbox = [line[1], line[2], line[3], line[4], videoId, trackId, imNum, classId, occl]\n",
        "    bboxes.append(bbox)\n",
        "    imNum+= 1\n",
        "bboxes = np.array(bboxes)\n",
        "\n",
        "if not os.path.exists(test_labels_path):\n",
        "    os.makedirs(test_labels_path)\n",
        "np.save(test_labels_path + \"/labels.npy\", bboxes)"
      ],
      "metadata": {
        "id": "aKwvFDjdS0G6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n"
      ],
      "metadata": {
        "id": "nDb8E1wHUj99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 training/get_datasets.py"
      ],
      "metadata": {
        "id": "M399FTVgqUyy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/training\n",
        "!python unrolled_solver.py -rtc -n 2 -b 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBjg9jtHFiPd",
        "outputId": "ff481f34-065e-4be7-c2b8-3e078ccbe698"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/training\n",
            "2023-10-08 13:17:34.626713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-08 13:17:35.656895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "#my_dataset keys: 284\n",
            "Restoring\n",
            "restoring from /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/logs/checkpoints\n",
            "No checkpoints found\n",
            "Restored 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/training/unrolled_solver.py\", line 90, in main\n",
            "    train_logger.network_conv_summary(network, iteration)\n",
            "  File \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/re3_utils/pytorch_util/tensorboard_logger.py\", line 104, in network_conv_summary\n",
            "    self.conv_variable_summaries(val, step, name, False)\n",
            "  File \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/re3_utils/pytorch_util/tensorboard_logger.py\", line 136, in conv_variable_summaries\n",
            "    self.image_summary(scope, summary_image, step, increment_counter)\n",
            "  File \"/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/re3_utils/pytorch_util/tensorboard_logger.py\", line 145, in image_summary\n",
            "    scipy.misc.toimage(img).save(s, format=\"png\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/misc/__init__.py\", line 45, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: scipy.misc is deprecated and has no attribute toimage.\n",
            "Saving...\n",
            "Saved /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/logs//checkpoints/iteration_0000000.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch/\n",
        "import os.path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))\n",
        "\n",
        "from re3_utils.pytorch_util import pytorch_util_functions as pt_util\n",
        "from re3_utils.pytorch_util.CaffeLSTMCell import CaffeLSTMCell\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Helper module that consists of a Conv -> Norm -> ReLU\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.bn = nn.GroupNorm(32, out_channels)\n",
        "        self.nonlinearity = nn.ELU(inplace=True)\n",
        "        self.with_nonlinearity = with_nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.with_nonlinearity:\n",
        "            x = self.nonlinearity(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Re3NetBase(nn.Module):\n",
        "    def __init__(self, device, args=None):\n",
        "        super(Re3NetBase, self).__init__()\n",
        "        self.device = device\n",
        "        self.args = args\n",
        "        self.learning_rate = None\n",
        "        self.optimizer = None\n",
        "        self.outputs = None\n",
        "\n",
        "    def loss(self, outputs, labels):\n",
        "        l1_loss = F.l1_loss(outputs, labels)\n",
        "        return l1_loss\n",
        "\n",
        "    def setup_optimizer(self, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=0.0005)\n",
        "\n",
        "    def update_learning_rate(self, lr_new):\n",
        "        if self.learning_rate != lr_new:\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group[\"lr\"] = lr_new\n",
        "            self.learning_rate = lr_new\n",
        "\n",
        "    def step(self, inputs, labels):\n",
        "        self.optimizer.zero_grad()\n",
        "        self.outputs = self(inputs)\n",
        "        loss = self.loss(self.outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.data.cpu().numpy()[0]\n",
        "\n",
        "\n",
        "class Re3Net(Re3NetBase):\n",
        "    def __init__(self, device, lstm_size=1024, args=None):\n",
        "        super(Re3Net, self).__init__(device, args)\n",
        "        self.device = device\n",
        "        self.lstm_size = lstm_size\n",
        "        self.conv = nn.ModuleList(\n",
        "            [\n",
        "                nn.Conv2d(3, 96, 11, stride=4, padding=0),\n",
        "                nn.Conv2d(96, 256, 5, padding=2, groups=2),\n",
        "                nn.Conv2d(256, 384, 3, padding=1),\n",
        "                nn.Conv2d(384, 384, 3, padding=1, groups=2),\n",
        "                nn.Conv2d(384, 256, 3, padding=1, groups=2),\n",
        "            ]\n",
        "        )\n",
        "        self.lrn = nn.ModuleList(\n",
        "            [\n",
        "                nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "                nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.conv_skip = nn.ModuleList([nn.Conv2d(96, 16, 1), nn.Conv2d(256, 32, 1), nn.Conv2d(256, 64, 1), ])\n",
        "        self.prelu_skip = nn.ModuleList([torch.nn.PReLU(16), torch.nn.PReLU(32), torch.nn.PReLU(64)])\n",
        "\n",
        "        self.fc6 = nn.Linear(74208, 2048)\n",
        "\n",
        "        self.lstm1 = CaffeLSTMCell(2048, self.lstm_size)\n",
        "        self.lstm2 = CaffeLSTMCell(2048 + self.lstm_size, self.lstm_size)\n",
        "\n",
        "        self.lstm_state = None\n",
        "\n",
        "        self.fc_output_out = nn.Linear(self.lstm_size, 4)\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Lambda(lambda x: x if len(x.shape) == 4 else pt_util.remove_dim(x, 1)),\n",
        "                transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "                transforms.Lambda(\n",
        "                    lambda x: pt_util.normalize(\n",
        "                        x,\n",
        "                        mean=np.array([123.151630838, 115.902882574, 103.062623801], dtype=np.float32)[\n",
        "                             np.newaxis, np.newaxis, np.newaxis, :\n",
        "                             ],\n",
        "                    )\n",
        "                ),\n",
        "                transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, input, lstm_state=None):\n",
        "        batch_size = input.shape[0]\n",
        "        input = self.transform(input).to(device=self.device)\n",
        "        conv1 = self.conv[0](input)\n",
        "        pool1 = F.relu(F.max_pool2d(conv1, (3, 3), stride=2))\n",
        "        lrn1 = self.lrn[0](pool1)\n",
        "\n",
        "        conv1_skip = self.prelu_skip[0](self.conv_skip[0](lrn1))\n",
        "        conv1_skip_flat = pt_util.remove_dim(conv1_skip, [2, 3])\n",
        "\n",
        "        conv2 = self.conv[1](lrn1)\n",
        "        pool2 = F.relu(F.max_pool2d(conv2, (3, 3), stride=2))\n",
        "        lrn2 = self.lrn[1](pool2)\n",
        "\n",
        "        conv2_skip = self.prelu_skip[1](self.conv_skip[1](lrn2))\n",
        "        conv2_skip_flat = pt_util.remove_dim(conv2_skip, [2, 3])\n",
        "\n",
        "        conv3 = F.relu(self.conv[2](lrn2))\n",
        "        conv4 = F.relu(self.conv[3](conv3))\n",
        "        conv5 = F.relu(self.conv[4](conv4))\n",
        "        pool5 = F.relu(F.max_pool2d(conv5, (3, 3), stride=2))\n",
        "        pool5_flat = pt_util.remove_dim(pool5, [2, 3])\n",
        "\n",
        "        conv5_skip = self.prelu_skip[2](self.conv_skip[2](conv5))\n",
        "        conv5_skip_flat = pt_util.remove_dim(conv5_skip, [2, 3])\n",
        "\n",
        "        skip_concat = torch.cat([conv1_skip_flat, conv2_skip_flat, conv5_skip_flat, pool5_flat], 1)\n",
        "        skip_concat = pt_util.split_axis(skip_concat, 0, -1, 2)\n",
        "        reshaped = pt_util.remove_dim(skip_concat, 2)\n",
        "\n",
        "        fc6 = F.relu(self.fc6(reshaped))\n",
        "\n",
        "        if lstm_state is None:\n",
        "            outputs1, state1 = self.lstm1(fc6)\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1))\n",
        "        else:\n",
        "            outputs1, state1, outputs2, state2 = lstm_state\n",
        "            outputs1, state1 = self.lstm1(fc6, (outputs1, state1))\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1), (outputs2, state2))\n",
        "\n",
        "        self.lstm_state = (outputs1, state1, outputs2, state2)\n",
        "\n",
        "        fc_output_out = self.fc_output_out(outputs2)\n",
        "        return fc_output_out\n",
        "\n",
        "\n",
        "class Re3SmallNet(Re3NetBase):\n",
        "    def __init__(self, device, lstm_size=512, args=None):\n",
        "        super(Re3SmallNet, self).__init__(device, args)\n",
        "        self.lstm_size = lstm_size\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=32, padding=3, kernel_size=7, stride=4),\n",
        "            ConvBlock(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Lambda(lambda x: x if len(x.shape) == 4 else pt_util.remove_dim(x, 1)),\n",
        "                transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "                transforms.Lambda(\n",
        "                    lambda x: pt_util.normalize(\n",
        "                        x,\n",
        "                        mean=np.array([123.675, 116.28, 103.53])[np.newaxis, np.newaxis, np.newaxis, :],\n",
        "                        std=np.array([58.395, 57.12, 57.375])[np.newaxis, np.newaxis, np.newaxis, :],\n",
        "                    )\n",
        "                ),\n",
        "                transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.fc6 = nn.Linear(50176, 2048)\n",
        "        self.lstm1 = nn.LSTMCell(2048, self.lstm_size)\n",
        "        self.lstm2 = nn.LSTMCell(2048 + self.lstm_size, self.lstm_size)\n",
        "        self.fc_output = nn.Sequential(\n",
        "            nn.Linear(self.lstm_size, self.lstm_size), nn.ELU(inplace=True), nn.Linear(self.lstm_size, 4)\n",
        "        )\n",
        "        self.learning_rate = None\n",
        "        self.optimizer = None\n",
        "        self.outputs = None\n",
        "        self.lstm_state = None\n",
        "\n",
        "    def forward(self, input, lstm_state=None):\n",
        "        x = input.to(self.device, dtype=torch.float32)\n",
        "        x = self.transform(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        x = pt_util.split_axis(x, 0, -1, 2)\n",
        "        x = pt_util.remove_dim(x, (2, 3, 4))\n",
        "\n",
        "        fc6 = F.elu(self.fc6(x))\n",
        "\n",
        "        if lstm_state is None:\n",
        "            outputs1, state1 = self.lstm1(fc6)\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1))\n",
        "        else:\n",
        "            outputs1, state1, outputs2, state2 = lstm_state\n",
        "            outputs1, state1 = self.lstm1(fc6, (outputs1, state1))\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1), (outputs2, state2))\n",
        "\n",
        "        self.lstm_state = (outputs1, state1, outputs2, state2)\n",
        "\n",
        "        output = self.fc_output(outputs2)\n",
        "        return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ePLDlbqaEOq",
        "outputId": "4ef9484b-68b0-4db6-ab9c-ecab7568b902"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZQt5KSqbHym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}