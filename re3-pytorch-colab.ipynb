{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkQ/MZtrRmNDL7AcZIQ8t5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haminhtien99/re3-pytorch/blob/master/re3-pytorch-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xây dựng mạng từ ban đầu. Cấu trúc mạng làm theo tác giả re3-pytorch"
      ],
      "metadata": {
        "id": "rCEl6NqMxptS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library"
      ],
      "metadata": {
        "id": "fCCBYeGTx5ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "LUFNOPFtx47l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6929963-994c-49b5-946c-3e3bb6ec8740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/275.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=3e52f05c621bc42f397bf489379b165276e46ee74392309089314ad65f5b6b72\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj7wKtwnxVMo"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from mpl_toolkits import mplot3d\n",
        "from matplotlib import gridspec\n",
        "from PIL import Image\n",
        "import io\n",
        "from urllib.request import urlopen\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os.path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uaIn9yOhyI_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ea32df-0cf5-488a-be52-bb7f18ff0ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch\n",
        "from re3_utils.pytorch_util import pytorch_util_functions as pt_util\n",
        "from re3_utils.pytorch_util.CaffeLSTMCell import CaffeLSTMCell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imN080CJCvms",
        "outputId": "4ec123ac-c6fa-4639-a0cf-c0b79acdde3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Re3-Object-Tracking/re3-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Z4eGOPUox_1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "EAYei_PIyA_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8a79e9-8089-4506-d99f-d89c405e7d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train network"
      ],
      "metadata": {
        "id": "C0tamZ1pyCEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    output = model(x_batch.to(device))\n",
        "\n",
        "    loss = loss_function(output, y_batch.to(device))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    return loss.cpu().item()"
      ],
      "metadata": {
        "id": "i2tCoRi2yKSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_generator, model, loss_function, optimizer, callback = None):\n",
        "    epoch_loss = 0\n",
        "    total = 0\n",
        "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
        "        batch_loss = train_on_batch(model, batch_of_x.to(device), batch_of_y.to(device), optimizer, loss_function)\n",
        "\n",
        "        if callback is not None:\n",
        "            callback(model, batch_loss)\n",
        "\n",
        "        epoch_loss += batch_loss*len(batch_of_x)\n",
        "        total += len(batch_of_x)\n",
        "\n",
        "    return epoch_loss/total"
      ],
      "metadata": {
        "id": "DO3rlrhLyTdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(count_of_epoch,\n",
        "            batch_size,\n",
        "            dataset,\n",
        "            model,\n",
        "            loss_function,\n",
        "            optimizer,\n",
        "            lr = 0.001,\n",
        "            callback = None):\n",
        "\n",
        "    optima = optimizer(model.parameters(), lr=lr)\n",
        "\n",
        "    iterations = tqdm(range(count_of_epoch), desc='epoch')\n",
        "    iterations.set_postfix({'train epoch loss': np.nan})\n",
        "    for it in iterations:\n",
        "        batch_generator = tqdm(\n",
        "            torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True),\n",
        "            leave=False, total=len(dataset)//batch_size+(len(dataset)%batch_size> 0))\n",
        "\n",
        "        epoch_loss = train_epoch(train_generator=batch_generator,\n",
        "                    model=model,\n",
        "                    loss_function=loss_function,\n",
        "                    optimizer=optima,\n",
        "                    callback=callback)\n",
        "\n",
        "        iterations.set_postfix({'train epoch loss': epoch_loss})"
      ],
      "metadata": {
        "id": "Sy2A7theyWCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Structure"
      ],
      "metadata": {
        "id": "uurJ7lFdyfTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Helper module that consists of a Conv -> Norm -> ReLU\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.bn = nn.GroupNorm(32, out_channels)\n",
        "        self.nonlinearity = nn.ELU(inplace=True)\n",
        "        self.with_nonlinearity = with_nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.with_nonlinearity:\n",
        "            x = self.nonlinearity(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xk9Tv6qVyVXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Re3SmallNet(nn.Module):\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "    def __init__(self, lstm_size=512, args=None):\n",
        "        super(Re3SmallNet, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=32, padding=3, kernel_size=7, stride=4),\n",
        "            ConvBlock(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBlock(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Lambda(lambda x: x if len(x.shape) == 4 else pt_util.remove_dim(x, 1)),\n",
        "                transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "                transforms.Lambda(\n",
        "                    lambda x: pt_util.normalize(\n",
        "                        x,\n",
        "                        mean=np.array([123.675, 116.28, 103.53])[np.newaxis, np.newaxis, np.newaxis, :],\n",
        "                        std=np.array([58.395, 57.12, 57.375])[np.newaxis, np.newaxis, np.newaxis, :],\n",
        "                    )\n",
        "                ),\n",
        "                transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.fc6 = nn.Sequential(\n",
        "            nn.Linear(50176, 2048),\n",
        "            nn.ELU()\n",
        "        )\n",
        "        self.lstm1 = nn.LSTMCell(2048, self.lstm_size)\n",
        "        self.lstm2 = nn.LSTMCell(2048 + self.lstm_size, self.lstm_size)\n",
        "        self.fc_output = nn.Sequential(\n",
        "            nn.Linear(self.lstm_size, self.lstm_size), nn.ELU(inplace=True), nn.Linear(self.lstm_size, 4)\n",
        "        )\n",
        "        self.learning_rate = None\n",
        "        self.optimizer = None\n",
        "        self.outputs = None\n",
        "        self.lstm_state = None\n",
        "\n",
        "    def forward(self, input, lstm_state=None):\n",
        "        x = input.to(self.device, dtype=torch.float32)\n",
        "        x = self.transform(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        x = pt_util.split_axis(x, 0, -1, 2)\n",
        "        x = pt_util.remove_dim(x, (2, 3, 4))\n",
        "\n",
        "        fc6 = self.fc6(x)\n",
        "\n",
        "        if lstm_state is None:\n",
        "            outputs1, state1 = self.lstm1(fc6)\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1))\n",
        "        else:\n",
        "            outputs1, state1, outputs2, state2 = lstm_state\n",
        "            outputs1, state1 = self.lstm1(fc6, (outputs1, state1))\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1), (outputs2, state2))\n",
        "\n",
        "        self.lstm_state = (outputs1, state1, outputs2, state2)\n",
        "\n",
        "        output = self.fc_output(outputs2)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "QGi-kwi8sKYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Re3Net(nn.Module):\n",
        "    def __init__(self, lstm_size=1024, args=None):\n",
        "        super(Re3Net, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.conv = nn.ModuleList(\n",
        "            [\n",
        "                nn.Conv2d(3, 96, 11, stride=4, padding=0),\n",
        "                nn.Conv2d(96, 256, 5, padding=2, groups=2),\n",
        "                nn.Conv2d(256, 384, 3, padding=1),\n",
        "                nn.Conv2d(384, 384, 3, padding=1, groups=2),\n",
        "                nn.Conv2d(384, 256, 3, padding=1, groups=2),\n",
        "            ]\n",
        "        )\n",
        "        self.lrn = nn.ModuleList(\n",
        "            [\n",
        "                nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "                nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.conv_skip = nn.ModuleList([nn.Conv2d(96, 16, 1), nn.Conv2d(256, 32, 1), nn.Conv2d(256, 64, 1), ])\n",
        "        self.prelu_skip = nn.ModuleList([nn.PReLU(16), nn.PReLU(32), nn.PReLU(64)])\n",
        "\n",
        "        self.fc6 = nn.Linear(74208, 2048)\n",
        "\n",
        "        self.lstm1 = CaffeLSTMCell(2048, self.lstm_size)\n",
        "        self.lstm2 = CaffeLSTMCell(2048 + self.lstm_size, self.lstm_size)\n",
        "\n",
        "        self.lstm_state = None\n",
        "\n",
        "        self.fc_output_out = nn.Linear(self.lstm_size, 4)\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Lambda(lambda x: x if len(x.shape) == 4 else pt_util.remove_dim(x, 1)),\n",
        "                transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "                transforms.Lambda(\n",
        "                    lambda x: pt_util.normalize(\n",
        "                        x,\n",
        "                        mean=np.array([123.151630838, 115.902882574, 103.062623801], dtype=np.float32)[\n",
        "                             np.newaxis, np.newaxis, np.newaxis, :\n",
        "                             ],\n",
        "                    )\n",
        "                ),\n",
        "                transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, input, lstm_state=None):\n",
        "        batch_size = input.shape[0]\n",
        "        input = self.transform(input).to(device=self.device)\n",
        "        conv1 = self.conv[0](input)\n",
        "        pool1 = F.relu(F.max_pool2d(conv1, (3, 3), stride=2))\n",
        "        lrn1 = self.lrn[0](pool1)\n",
        "\n",
        "        conv1_skip = self.prelu_skip[0](self.conv_skip[0](lrn1))\n",
        "        conv1_skip_flat = pt_util.remove_dim(conv1_skip, [2, 3])\n",
        "\n",
        "        conv2 = self.conv[1](lrn1)\n",
        "        pool2 = F.relu(F.max_pool2d(conv2, (3, 3), stride=2))\n",
        "        lrn2 = self.lrn[1](pool2)\n",
        "\n",
        "        conv2_skip = self.prelu_skip[1](self.conv_skip[1](lrn2))\n",
        "        conv2_skip_flat = pt_util.remove_dim(conv2_skip, [2, 3])\n",
        "\n",
        "        conv3 = F.relu(self.conv[2](lrn2))\n",
        "        conv4 = F.relu(self.conv[3](conv3))\n",
        "        conv5 = F.relu(self.conv[4](conv4))\n",
        "        pool5 = F.relu(F.max_pool2d(conv5, (3, 3), stride=2))\n",
        "        pool5_flat = pt_util.remove_dim(pool5, [2, 3])\n",
        "\n",
        "        conv5_skip = self.prelu_skip[2](self.conv_skip[2](conv5))\n",
        "        conv5_skip_flat = pt_util.remove_dim(conv5_skip, [2, 3])\n",
        "\n",
        "        skip_concat = torch.cat([conv1_skip_flat, conv2_skip_flat, conv5_skip_flat, pool5_flat], 1)\n",
        "        skip_concat = pt_util.split_axis(skip_concat, 0, -1, 2)\n",
        "        reshaped = pt_util.remove_dim(skip_concat, 2)\n",
        "\n",
        "        fc6 = F.relu(self.fc6(reshaped))\n",
        "\n",
        "        if lstm_state is None:\n",
        "            outputs1, state1 = self.lstm1(fc6)\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1))\n",
        "        else:\n",
        "            outputs1, state1, outputs2, state2 = lstm_state\n",
        "            outputs1, state1 = self.lstm1(fc6, (outputs1, state1))\n",
        "            outputs2, state2 = self.lstm2(torch.cat((fc6, outputs1), 1), (outputs2, state2))\n",
        "\n",
        "        self.lstm_state = (outputs1, state1, outputs2, state2)\n",
        "\n",
        "        fc_output_out = self.fc_output_out(outputs2)\n",
        "        return fc_output_out"
      ],
      "metadata": {
        "id": "ORjgjI03DfMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= Re3SmallNet()\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxpUYHQCJ6-7",
        "outputId": "afdf1d64-a76f-4abc-ef2e-0af4cefa8814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Re3SmallNet(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
              "      (bn): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
              "      (nonlinearity): ELU(alpha=1.0, inplace=True)\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "      (nonlinearity): ELU(alpha=1.0, inplace=True)\n",
              "    )\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): ConvBlock(\n",
              "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "      (nonlinearity): ELU(alpha=1.0, inplace=True)\n",
              "    )\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): ConvBlock(\n",
              "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (nonlinearity): ELU(alpha=1.0, inplace=True)\n",
              "    )\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): ConvBlock(\n",
              "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "      (nonlinearity): ELU(alpha=1.0, inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (fc6): Sequential(\n",
              "    (0): Linear(in_features=50176, out_features=2048, bias=True)\n",
              "    (1): ELU(alpha=1.0)\n",
              "  )\n",
              "  (lstm1): LSTMCell(2048, 512)\n",
              "  (lstm2): LSTMCell(2560, 512)\n",
              "  (fc_output): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ELU(alpha=1.0, inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}